{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea84ac6",
   "metadata": {},
   "source": [
    "# NegMerge Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134ccd8",
   "metadata": {},
   "source": [
    "## 1. Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a03f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import sys\n",
    "import timm.data.transforms\n",
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ipykernel' in sys.modules:\n",
    "    sys.argv = ['']\n",
    "\n",
    "class MaybeToTensor:\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "timm.data.transforms.MaybeToTensor = MaybeToTensor\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ca41c",
   "metadata": {},
   "source": [
    "## 2. Define Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_location\", type=str, default=os.path.expanduser(\"~/data\"), help=\"The root directory for the datasets.\")\n",
    "    parser.add_argument(\"--eval-datasets\", default=None, type=lambda x: x.split(\",\"), help=\"Which datasets to use for evaluation. Split by comma, e.g. MNIST,EuroSAT.\")\n",
    "    parser.add_argument(\"--results_db\", type=str, default=None, help=\"Where to store the results, else does not store\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"ViT-B-32\", help=\"The type of model (e.g. RN50, ViT-B-32).\")\n",
    "    parser.add_argument(\"--save\", type=str, default=None, help=\"Optionally save a _classifier_, e.g. a zero shot classifier or probe.\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=None, help=\"Random seed.\")\n",
    "    parser.add_argument(\"--finetuning_mode\", choices=[\"standard\", \"linear\", \"none\"], help=\"Whether to use linearized models or not.\")\n",
    "    parser.add_argument(\"--n-eval-points\", type=int, default=21, help=\"Number of evaluation points used to find optimal coefficient in task arithmetic.\")\n",
    "\n",
    "    parsed_args = parser.parse_args()\n",
    "    parsed_args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    if parsed_args.load is not None and len(parsed_args.load) == 1:\n",
    "        parsed_args.load = parsed_args.load[0]\n",
    "        \n",
    "    return parsed_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b740d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_arguments()\n",
    "\n",
    "args.data_location = \"dataset/\"\n",
    "args.finetuning_mode = \"standard\"       # \"linear\" or \"standard\"\n",
    "args.model = \"ViT-B-32\"                 # Backbone\n",
    "args.results_db = \"checkpoints\"\n",
    "args.save = os.path.join(args.results_db, args.finetuning_mode, args.model)\n",
    "\n",
    "dataset = \"Cars\"                        # Forget set\n",
    "control_dataset = \"ImageNet\"            # Retain set\n",
    "\n",
    "with open(os.path.join(\"/path/to/zeroshot_accuracies.json\")) as f:\n",
    "    pretrained_accuracies = json.load(f)\n",
    "negation_accuracies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eaff29",
   "metadata": {},
   "source": [
    "## 3. Dowload Pretrained and Fine-tuned Weights\n",
    "- Download Link: https://drive.google.com/drive/u/1/folders/1m1iHi5KoTN1Fg5JqIZxtVP1ZTxgILZyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = '/path/to/zeroshot.pt'\n",
    "finetuned_paths = [\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m1-n1_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m1-n2_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m1-n3_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m2-n1_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m2-n2_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m2-n3_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m3-n1_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m3-n2_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m3-n3_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m4-n1_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m4-n2_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m4-n3_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m5-n1_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m5-n2_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m5-n3_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m6-n1_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m6-n2_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m6-n3_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m7-n1_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m7-n2_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m7-n3_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m8-n1_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m8-n2_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m8-n3_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m9-n1_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m9-n2_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m9-n3_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m10-n1_finetuned.pt',\n",
    "    '/path/to/clip-vit-b-32_cars_rand-m10-n2_finetuned.pt', '/path/to/clip-vit-b-32_cars_rand-m10-n3_finetuned.pt'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809e62b9",
   "metadata": {},
   "source": [
    "## 4. Define Task Vector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64aa4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TaskVector(abc.ABC):\n",
    "    def __init__(\n",
    "        self, pretrained_checkpoint=None, finetuned_checkpoint=None, vector=None\n",
    "    ):\n",
    "        if vector is not None:\n",
    "            self.vector = vector\n",
    "        else:\n",
    "            assert (\n",
    "                pretrained_checkpoint is not None and finetuned_checkpoint is not None\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                if isinstance(pretrained_checkpoint, dict):\n",
    "                    pretrained_state_dict = pretrained_checkpoint\n",
    "                else:\n",
    "                    pretrained_state_dict = self._load_checkpoint(\n",
    "                        pretrained_checkpoint\n",
    "                    ).state_dict()\n",
    "\n",
    "                if isinstance(finetuned_checkpoint, dict):\n",
    "                    finetuned_state_dict = finetuned_checkpoint\n",
    "                else:\n",
    "                    finetuned_state_dict = self._load_checkpoint(\n",
    "                        finetuned_checkpoint\n",
    "                    ).state_dict()\n",
    "\n",
    "                self.vector = {}\n",
    "                for key in pretrained_state_dict:\n",
    "                    if pretrained_state_dict[key].dtype == torch.int64:\n",
    "                        continue\n",
    "                    if pretrained_state_dict[key].dtype == torch.uint8:\n",
    "                        continue\n",
    "                    self.vector[key] = (\n",
    "                        finetuned_state_dict[key] - pretrained_state_dict[key]\n",
    "                    )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _load_checkpoint(self, checkpoint):\n",
    "        \"\"\"Load a checkpoint into a model.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _cast_to_same_type(self, other):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"Add two task vectors together.\"\"\"\n",
    "        other = self._cast_to_same_type(other)\n",
    "        with torch.no_grad():\n",
    "            new_vector = {}\n",
    "            for key in self.vector:\n",
    "                if key not in other.vector:\n",
    "                    print(f\"Warning, key {key} is not present in both task vectors.\")\n",
    "                    continue\n",
    "                new_vector[key] = self.vector[key] + other.vector[key]\n",
    "        return self.__class__(vector=new_vector)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"Subtract two task vectors.\"\"\"\n",
    "        return self.__add__(-other)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if other is None or isinstance(other, int):\n",
    "            return self\n",
    "        return self.__add__(other)\n",
    "\n",
    "    def __neg__(self):\n",
    "        \"\"\"Negate a task vector.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            new_vector = {}\n",
    "            for key in self.vector:\n",
    "                new_vector[key] = -self.vector[key]\n",
    "        return self.__class__(vector=new_vector)\n",
    "\n",
    "    def __pow__(self, power):\n",
    "        \"\"\"Power of a task vector.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            new_vector = {}\n",
    "            for key in self.vector:\n",
    "                new_vector[key] = self.vector[key] ** power\n",
    "        return self.__class__(vector=new_vector)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        \"\"\"Multiply a task vector by a scalar.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            new_vector = {}\n",
    "            for key in self.vector:\n",
    "                new_vector[key] = other * self.vector[key]\n",
    "        return self.__class__(vector=new_vector)\n",
    "\n",
    "    def dot(self, other):\n",
    "        \"\"\"Dot product of two task vectors.\"\"\"\n",
    "        other = self._cast_to_same_type(other)\n",
    "        with torch.no_grad():\n",
    "            dot_product = 0.0\n",
    "            for key in self.vector:\n",
    "                if key not in other.vector:\n",
    "                    print(f\"Warning, key {key} is not present in both task vectors.\")\n",
    "                    continue\n",
    "                dot_product += torch.sum(self.vector[key] * other.vector[key])\n",
    "        return dot_product\n",
    "\n",
    "    def norm(self):\n",
    "        \"\"\"Norm of a task vector.\"\"\"\n",
    "        return torch.sqrt(self.dot(self))\n",
    "\n",
    "    def apply_to(self, pretrained_checkpoint, scaling_coef=1.0):\n",
    "        \"\"\"Apply a task vector to a pretrained model.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            pretrained_model = self._load_checkpoint(pretrained_checkpoint)\n",
    "            new_state_dict = {}\n",
    "            pretrained_state_dict = pretrained_model.state_dict()\n",
    "            for key in pretrained_state_dict:\n",
    "                if key not in self.vector:\n",
    "                    print(\n",
    "                        f\"Warning: key {key} is present in the pretrained state dict but not in the task vector\"  # noqa: E501\n",
    "                    )\n",
    "                    continue\n",
    "                new_state_dict[key] = (\n",
    "                    pretrained_state_dict[key] + scaling_coef * self.vector[key]\n",
    "                )\n",
    "        pretrained_model.load_state_dict(new_state_dict)\n",
    "        return pretrained_model\n",
    "\n",
    "\n",
    "class NonLinearTaskVector(_TaskVector):\n",
    "    \"\"\"A task vector for nonlinear models.\"\"\"\n",
    "\n",
    "    def _load_checkpoint(self, checkpoint):\n",
    "        \"\"\"Load a checkpoint into a model.\"\"\"\n",
    "        return torch.load(checkpoint, map_location=\"cpu\")\n",
    "\n",
    "    def apply_to_nonlinear(self, pretrained_nonlinear_checkpoint, scaling_coef=1.0):\n",
    "        \"\"\"Apply a task vector to a nonlinear pretrained model.\"\"\"\n",
    "        return self.apply_to(pretrained_nonlinear_checkpoint, scaling_coef)\n",
    "    \n",
    "    def _cast_to_same_type(self, other):\n",
    "        return linear_to_nonlinear(other, self.vector.keys())\n",
    "\n",
    "def linear_to_nonlinear(linear_task_vector, param_names):\n",
    "    \"\"\"Convert a linear task vector to a nonlinear task vector.\"\"\"\n",
    "    if isinstance(linear_task_vector, NonLinearTaskVector):\n",
    "        return linear_task_vector\n",
    "    else:\n",
    "        return NonLinearTaskVector(\n",
    "            vector=linear_task_vector.get_named_parameters(param_names)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd9424",
   "metadata": {},
   "source": [
    "## 5. Merge Task Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08834012-6c57-4709-927d-6b1234a825c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, finetuned_path in enumerate(finetuned_paths):\n",
    "    state_dict = torch.load(finetuned_path, map_location=device)\n",
    "    state_dict = {k: v.to(device) for k, v in state_dict.items()}\n",
    "        \n",
    "    task_vector = (NonLinearTaskVector(pretrained_path, state_dict))\n",
    "\n",
    "    if idx == 0:\n",
    "        merged_vector = {k: torch.zeros_like(v) for k, v in task_vector.vector.items()}\n",
    "        mask = {k: torch.zeros_like(v) for k, v in task_vector.vector.items()}\n",
    "\n",
    "    for key in task_vector.vector.keys():\n",
    "        merged_vector[key] += task_vector.vector[key]\n",
    "        mask[key] += torch.sign(task_vector.vector[key])\n",
    "\n",
    "for key in torch.load(finetuned_path).keys():\n",
    "    consistency_mask = torch.abs(mask[key]) == len(finetuned_paths)\n",
    "    task_vector.vector[key] = torch.where(consistency_mask, merged_vector[key] / len(finetuned_paths), torch.zeros_like(merged_vector[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e2351",
   "metadata": {},
   "source": [
    "## 6. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77709dcb",
   "metadata": {},
   "source": [
    "### 6.1. Find Optimal Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268d4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for scaling coefficient 0.00\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 59.58%\n",
      "CarsVal Top-1 accuracy: 0.5958\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.70%\n",
      "ImageNetVal Top-1 accuracy: 0.6670\n",
      "Evaluating for scaling coefficient 0.05\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 58.11%\n",
      "CarsVal Top-1 accuracy: 0.5811\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.66%\n",
      "ImageNetVal Top-1 accuracy: 0.6666\n",
      "Evaluating for scaling coefficient 0.10\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 56.27%\n",
      "CarsVal Top-1 accuracy: 0.5627\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.50%\n",
      "ImageNetVal Top-1 accuracy: 0.6650\n",
      "Evaluating for scaling coefficient 0.15\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 54.05%\n",
      "CarsVal Top-1 accuracy: 0.5405\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.66%\n",
      "ImageNetVal Top-1 accuracy: 0.6666\n",
      "Evaluating for scaling coefficient 0.20\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 52.09%\n",
      "CarsVal Top-1 accuracy: 0.5209\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.50%\n",
      "ImageNetVal Top-1 accuracy: 0.6650\n",
      "Evaluating for scaling coefficient 0.25\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 50.12%\n",
      "CarsVal Top-1 accuracy: 0.5012\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.32%\n",
      "ImageNetVal Top-1 accuracy: 0.6632\n",
      "Evaluating for scaling coefficient 0.30\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 47.54%\n",
      "CarsVal Top-1 accuracy: 0.4754\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.14%\n",
      "ImageNetVal Top-1 accuracy: 0.6614\n",
      "Evaluating for scaling coefficient 0.35\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 45.82%\n",
      "CarsVal Top-1 accuracy: 0.4582\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.24%\n",
      "ImageNetVal Top-1 accuracy: 0.6624\n",
      "Evaluating for scaling coefficient 0.40\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 43.98%\n",
      "CarsVal Top-1 accuracy: 0.4398\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.18%\n",
      "ImageNetVal Top-1 accuracy: 0.6618\n",
      "Evaluating for scaling coefficient 0.45\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 42.26%\n",
      "CarsVal Top-1 accuracy: 0.4226\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 66.02%\n",
      "ImageNetVal Top-1 accuracy: 0.6602\n",
      "Evaluating for scaling coefficient 0.50\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 40.54%\n",
      "CarsVal Top-1 accuracy: 0.4054\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 65.70%\n",
      "ImageNetVal Top-1 accuracy: 0.6570\n",
      "Evaluating for scaling coefficient 0.55\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 38.94%\n",
      "CarsVal Top-1 accuracy: 0.3894\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 65.32%\n",
      "ImageNetVal Top-1 accuracy: 0.6532\n",
      "Evaluating for scaling coefficient 0.60\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 37.59%\n",
      "CarsVal Top-1 accuracy: 0.3759\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 65.32%\n",
      "ImageNetVal Top-1 accuracy: 0.6532\n",
      "Evaluating for scaling coefficient 0.65\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 36.24%\n",
      "CarsVal Top-1 accuracy: 0.3624\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 65.12%\n",
      "ImageNetVal Top-1 accuracy: 0.6512\n",
      "Evaluating for scaling coefficient 0.70\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 34.52%\n",
      "CarsVal Top-1 accuracy: 0.3452\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 64.90%\n",
      "ImageNetVal Top-1 accuracy: 0.6490\n",
      "Evaluating for scaling coefficient 0.75\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 33.05%\n",
      "CarsVal Top-1 accuracy: 0.3305\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 64.74%\n",
      "ImageNetVal Top-1 accuracy: 0.6474\n",
      "Evaluating for scaling coefficient 0.80\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 30.22%\n",
      "CarsVal Top-1 accuracy: 0.3022\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 64.16%\n",
      "ImageNetVal Top-1 accuracy: 0.6416\n",
      "Evaluating for scaling coefficient 0.85\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 28.62%\n",
      "CarsVal Top-1 accuracy: 0.2862\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 63.72%\n",
      "ImageNetVal Top-1 accuracy: 0.6372\n",
      "Evaluating for scaling coefficient 0.90\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 25.55%\n",
      "CarsVal Top-1 accuracy: 0.2555\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 63.54%\n",
      "ImageNetVal Top-1 accuracy: 0.6354\n",
      "Evaluating for scaling coefficient 0.95\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 24.20%\n",
      "CarsVal Top-1 accuracy: 0.2420\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:14<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 63.20%\n",
      "ImageNetVal Top-1 accuracy: 0.6320\n",
      "Evaluating for scaling coefficient 1.00\n",
      "Evaluating on CarsVal\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on CarsVal. Accuracy: 22.60%\n",
      "CarsVal Top-1 accuracy: 0.2260\n",
      "Evaluating on ImageNetVal\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:13<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNetVal. Accuracy: 62.74%\n",
      "ImageNetVal Top-1 accuracy: 0.6274\n",
      "Control metric fell below 0.6332699999999999 threshold\n",
      "Control metric fell below 0.6332699999999999 threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.eval import evaluate_task_vector, evaluate_task_vector_at_coef\n",
    "from src.utils import find_optimal_coef\n",
    "\n",
    "args.eval_datasets = [dataset + \"Val\"]\n",
    "args.control_dataset = control_dataset + \"Val\"\n",
    "val_metrics = evaluate_task_vector(\n",
    "    -task_vector,\n",
    "    pretrained_path,\n",
    "    args,\n",
    ")\n",
    "\n",
    "optimal_coef = find_optimal_coef(\n",
    "    val_metrics,\n",
    "    metric=f\"{dataset}Val:top1\",\n",
    "    minimize=True,\n",
    "    control_metric=f\"{control_dataset}Val:top1\",\n",
    "    control_metric_threshold=0.95 * pretrained_accuracies[control_dataset + \"Val\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a642fe",
   "metadata": {},
   "source": [
    "### 6.2. Evaluate on the test set with the optimal coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc040625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Cars\n",
      "Classification head for ViT-B-32 on CarsVal exists at checkpoints/standard/ViT-B-32/head_CarsVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_CarsVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:33<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on Cars. Accuracy: 27.40%\n",
      "Cars Top-1 accuracy: 0.2740\n",
      "Evaluating on ImageNet\n",
      "Classification head for ViT-B-32 on ImageNetVal exists at checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n",
      "Loading classification head from checkpoints/standard/ViT-B-32/head_ImageNetVal.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [03:30<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on ImageNet. Accuracy: 60.38%\n",
      "ImageNet Top-1 accuracy: 0.6038\n",
      "====================================================================================================\n",
      "Test accuracy: 0.27397089914189776\n",
      "{'test': 0.27397089914189776, 'test_control': 0.60378, 'val': {0.0: {'CarsVal:top1': 0.5958230958230958, 'ImageNetVal:top1': 0.667}, 0.05: {'CarsVal:top1': 0.581081081081081, 'ImageNetVal:top1': 0.6666}, 0.1: {'CarsVal:top1': 0.5626535626535627, 'ImageNetVal:top1': 0.665}, 0.15000000000000002: {'CarsVal:top1': 0.5405405405405406, 'ImageNetVal:top1': 0.6666}, 0.2: {'CarsVal:top1': 0.5208845208845209, 'ImageNetVal:top1': 0.665}, 0.25: {'CarsVal:top1': 0.5012285012285013, 'ImageNetVal:top1': 0.6632}, 0.30000000000000004: {'CarsVal:top1': 0.47542997542997545, 'ImageNetVal:top1': 0.6614}, 0.35000000000000003: {'CarsVal:top1': 0.4582309582309582, 'ImageNetVal:top1': 0.6624}, 0.4: {'CarsVal:top1': 0.4398034398034398, 'ImageNetVal:top1': 0.6618}, 0.45: {'CarsVal:top1': 0.4226044226044226, 'ImageNetVal:top1': 0.6602}, 0.5: {'CarsVal:top1': 0.40540540540540543, 'ImageNetVal:top1': 0.657}, 0.55: {'CarsVal:top1': 0.3894348894348894, 'ImageNetVal:top1': 0.6532}, 0.6000000000000001: {'CarsVal:top1': 0.3759213759213759, 'ImageNetVal:top1': 0.6532}, 0.65: {'CarsVal:top1': 0.36240786240786244, 'ImageNetVal:top1': 0.6512}, 0.7000000000000001: {'CarsVal:top1': 0.3452088452088452, 'ImageNetVal:top1': 0.649}, 0.75: {'CarsVal:top1': 0.33046683046683045, 'ImageNetVal:top1': 0.6474}, 0.8: {'CarsVal:top1': 0.3022113022113022, 'ImageNetVal:top1': 0.6416}, 0.8500000000000001: {'CarsVal:top1': 0.28624078624078625, 'ImageNetVal:top1': 0.6372}, 0.9: {'CarsVal:top1': 0.25552825552825553, 'ImageNetVal:top1': 0.6354}, 0.9500000000000001: {'CarsVal:top1': 0.24201474201474202, 'ImageNetVal:top1': 0.632}, 1.0: {'CarsVal:top1': 0.22604422604422605, 'ImageNetVal:top1': 0.6274}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args.eval_datasets = [dataset]\n",
    "args.control_dataset = control_dataset\n",
    "test_metrics = evaluate_task_vector_at_coef(\n",
    "    -task_vector,\n",
    "    pretrained_path,\n",
    "    args,\n",
    "    optimal_coef,\n",
    ")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"Test accuracy: {test_metrics[f'{dataset}:top1']}\")\n",
    "\n",
    "negation_accuracies[dataset] = {\n",
    "    \"test\": test_metrics[f\"{dataset}:top1\"],\n",
    "    \"test_control\": test_metrics[f\"{control_dataset}:top1\"],\n",
    "    \"val\": val_metrics,\n",
    "}\n",
    "\n",
    "print(negation_accuracies[dataset])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (negmerge-clip)",
   "language": "python",
   "name": "negmerge-clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
